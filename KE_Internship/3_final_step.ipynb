{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-21T11:06:23.689966Z",
     "start_time": "2022-04-21T11:06:23.372847Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-21T11:06:23.695380Z",
     "start_time": "2022-04-21T11:06:23.692191Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "src_test_parquet = 'ke_test_data/test.parquet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-21T11:06:23.863458Z",
     "start_time": "2022-04-21T11:06:23.696807Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test = pq.read_table(src_test_parquet).to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-21T11:06:24.063546Z",
     "start_time": "2022-04-21T11:06:23.867993Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# загружаем результаты обучения\n",
    "from joblib import load\n",
    "\n",
    "DG = load('DG.pkl')\n",
    "model_params = load('model_params.pkl')\n",
    "catalogs = load('catalogs.pkl')\n",
    "cat2id = load('cat2id.pkl')\n",
    "train_catalogs = load('train_catalogs.pkl')\n",
    "train_cat2id = load('train_cat2id.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-21T11:06:24.070039Z",
     "start_time": "2022-04-21T11:06:24.065411Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def all_predcestors(g, id, max_len=7):\n",
    "    # циклично запрашиваем предков, пока их не будет совсем\n",
    "    all_preds = [id]\n",
    "    while True:\n",
    "        preds = list(g.predecessors(id))\n",
    "        if len(preds) == 0:\n",
    "            break\n",
    "        all_preds.append(preds[0])\n",
    "        id = all_preds[-1]\n",
    "\n",
    "    # доводим до максимального размера, чтобы вмещалось в tensor/array\n",
    "    # паддинг -1 (0 занят нашим каталогом, мы позже их закодируем, но всеравно...)\n",
    "    if len(all_preds) < max_len:\n",
    "        all_preds = [-1] * (max_len - len(all_preds)) + all_preds\n",
    "    return all_preds[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-21T11:06:24.079151Z",
     "start_time": "2022-04-21T11:06:24.071752Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def hist_edges_mapper(val, bin_borders=model_params['hist_bin_edges']):\n",
    "    # мэпим значения в диапазоны гистограммы\n",
    "    resval = []\n",
    "    for i in range(len(bin_borders)-1):\n",
    "        if bin_borders[i] <= val < bin_borders[i+1]:\n",
    "            resval.append(1)\n",
    "        elif i == len(bin_borders) - 2:\n",
    "            if val == bin_borders[i+1]:\n",
    "                resval.append(1)\n",
    "            else:\n",
    "                resval.append(0)\n",
    "        else:\n",
    "            resval.append(0)\n",
    "\n",
    "    global num_pbar\n",
    "    num_pbar.update(1)\n",
    "\n",
    "    return resval\n",
    "\n",
    "def get_text_data_func(x, sep=' '):\n",
    "    # дергает текстовые данные из входящего датафрейма\n",
    "    result = x.copy()\n",
    "    result['text'] = ''\n",
    "    for i, key in enumerate(model_params['text']):\n",
    "        if i != 0:\n",
    "            result['text'] = result['text'] + sep\n",
    "        result['text'] = result['text'] + result[key].astype(str)\n",
    "\n",
    "    return result['text'].to_numpy()\n",
    "\n",
    "def get_numeric_data_func(x):\n",
    "    # дергает числовые данные из входящего датафрейма\n",
    "    x = x[model_params['numeric']].copy()\n",
    "    column = model_params['numeric'][0]\n",
    "    x[column] = x[column].apply(hist_edges_mapper)\n",
    "    return pd.DataFrame(x['rating'].to_list()).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-21T11:06:24.087191Z",
     "start_time": "2022-04-21T11:06:24.080678Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# прогрессбары внутри пайплайна\n",
    "num_pbar = None\n",
    "text_pbar = None\n",
    "\n",
    "def start_num_pbar(x):\n",
    "    global num_pbar\n",
    "    num_pbar = tqdm(total=len(x), desc='Nums processing')\n",
    "    return x\n",
    "\n",
    "\n",
    "def shut_num_pbar(x):\n",
    "    global num_pbar\n",
    "    num_pbar.close()\n",
    "    return x\n",
    "\n",
    "\n",
    "def start_text_pbar(x):\n",
    "    global text_pbar\n",
    "    text_pbar = tqdm(total=len(x), desc='Text processing')\n",
    "    return x\n",
    "\n",
    "\n",
    "def shut_text_pbar(x):\n",
    "    global text_pbar\n",
    "    text_pbar.close()\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-21T11:06:24.096041Z",
     "start_time": "2022-04-21T11:06:24.088873Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# бинарные кодеры\\декодеры\n",
    "def dummify_labels(df_in, column, column_dict, catalogs):\n",
    "    \"\"\"\n",
    "    разбивает столбец датафрейма на бинарные столбцы из списка. Просто принцип onehot\n",
    "    \"\"\"\n",
    "    y = df_in[column].copy()\n",
    "    # ушли в \"примитивы\", поиск по пандасу значительно дольше.\n",
    "    out = np.zeros((len(y.index), len(catalogs)), dtype=float)\n",
    "\n",
    "    for i, cat in enumerate(y[column[0]].values):\n",
    "        cat_position = column_dict[cat]\n",
    "        out[i][cat_position] = 1\n",
    "\n",
    "    out = pd.DataFrame(out, index=y.index, columns=catalogs).astype(int)\n",
    "\n",
    "    return out\n",
    "\n",
    "def undummify_labels(df_dimmies, column, column_list):\n",
    "    \"\"\"\n",
    "    возвращает бинарные столбцы таргета в исходный один столбец.\n",
    "    \"\"\"\n",
    "\n",
    "    y = df_dimmies.to_numpy()\n",
    "    out = np.argmax(y, axis=1)\n",
    "    out = np.array([column_list[i] for i in out])\n",
    "\n",
    "    return pd.DataFrame(out, columns=column, index=df_dimmies.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-21T11:06:25.172771Z",
     "start_time": "2022-04-21T11:06:24.097692Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/kit-\n",
      "[nltk_data]     kat/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/kit-kat/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# свой токенайзер + стэммер  (так мы уменьшим размерность с ~80к до ~50к уникальных токенов\n",
    "import nltk\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "\n",
    "regex = r\"[\\s\\|$:*!?#:,.(){}\\\"\\'\\$\\^\\/\\\\\\[\\]\\-+”“%¡¿&;«»`\\d]\"\n",
    "\n",
    "punctuation = set(['\\t','\\n','\\\\', '', 'none'])\n",
    "\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download('punkt')\n",
    "\n",
    "russian_stopwords = set(stopwords.words(\"russian\"))  # список стоп слов\n",
    "\n",
    "\n",
    "class StemTokenizer:\n",
    "    # Стэммер вычленяет корни слов\n",
    "    def __init__(self):\n",
    "        self.stemer = SnowballStemmer('russian')\n",
    "    def __call__(self, doc):\n",
    "        # 1) делаем список токенов через regexp\n",
    "        # 2) делаем стэмминг корней слов\n",
    "        # 3) фильтруем полученные леммы через стоп слова\n",
    "        # 4) возвращаем список\n",
    "        regex_num_ponctuation = punctuation\n",
    "\n",
    "        resval = [self.stemer.stem(t) for t in re.split(regex, doc.lower())\n",
    "                if t not in regex_num_ponctuation and len(t) >= model_params['t_min_len']]\n",
    "\n",
    "        global text_pbar\n",
    "        text_pbar.update(1)\n",
    "\n",
    "        return resval\n",
    "\n",
    "\n",
    "from pymystem3 import Mystem\n",
    "\n",
    "class LemmaTokenizer():\n",
    "    # Лемматайзер приводит слова к неопределенному виду (сохраняется некоторый контекст)\n",
    "    # почти в два раза медленнее и на ~0,001 дает точности больше чем стэмер\n",
    "    # не пиклится :(\n",
    "    def __init__(self):\n",
    "        self.mystem = Mystem()\n",
    "\n",
    "    def __call__(self, doc):\n",
    "        # 1) делаем список токенов через regexp\n",
    "        # 2) делаем лемминг слов\n",
    "        # 3) фильтруем полученные леммы через стоп слова\n",
    "        # 4) возвращаем список\n",
    "\n",
    "        resval = []\n",
    "        for t in re.split(regex, doc.lower()):\n",
    "            lemma = self.mystem.lemmatize(t)  # позвращает список лемм\n",
    "            # tokens.extend(lemma)\n",
    "            for tt in lemma:\n",
    "                if tt not in punctuation and len(tt) >= model_params['t_min_len']:\n",
    "                    resval.append(tt)\n",
    "\n",
    "        global text_pbar\n",
    "        text_pbar.update(1)\n",
    "\n",
    "        return resval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-21T11:06:27.882355Z",
     "start_time": "2022-04-21T11:06:25.176548Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# загружаем обученную модель\n",
    "from joblib import load\n",
    "pl = load('pl.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-21T11:06:27.892059Z",
     "start_time": "2022-04-21T11:06:27.884525Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_test = test[model_params['text'] + model_params['numeric']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-21T11:07:14.513441Z",
     "start_time": "2022-04-21T11:06:27.893450Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Text processing: 100%|██████████| 70864/70864 [00:32<00:00, 2201.38it/s]\n"
     ]
    }
   ],
   "source": [
    "result = pl.predict_proba(X=X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-21T11:07:14.977610Z",
     "start_time": "2022-04-21T11:07:14.515488Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "result = pd.DataFrame(result, index=X_test.index, columns=train_catalogs)\n",
    "result = undummify_labels(result, model_params['labels'], train_catalogs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-21T11:07:14.986202Z",
     "start_time": "2022-04-21T11:07:14.979369Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test = test[['id']]\n",
    "test['predicted_category_id'] = result[model_params['labels'][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-21T11:07:15.004635Z",
     "start_time": "2022-04-21T11:07:14.987766Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>predicted_category_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1070974</td>\n",
       "      <td>11574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>450413</td>\n",
       "      <td>11878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>126857</td>\n",
       "      <td>13299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1577569</td>\n",
       "      <td>13061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>869328</td>\n",
       "      <td>12813</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  predicted_category_id\n",
       "0  1070974                  11574\n",
       "1   450413                  11878\n",
       "2   126857                  13299\n",
       "3  1577569                  13061\n",
       "4   869328                  12813"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-21T11:07:15.026833Z",
     "start_time": "2022-04-21T11:07:15.006047Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "table = pa.Table.from_pandas(test)\n",
    "pq.write_table(table, 'result.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-21T11:07:15.030883Z",
     "start_time": "2022-04-21T11:07:15.028435Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "exit(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}