Добрый день. Работа которую я сдавал на KazanExpress для прохождения стажировки   

Я не прошел. Занял 17 место из 50. Мой результат 0.8144, Топ 0.8639

Субъективно уступил, моделям с эмбедингами от Word2Vec, FastText.   

Опишу задачу, данную на соревнование:  
**Нужно для "но-нейм" товара сделать матчинг каталога, куда он больше всего подходит.**  
т.е. сделать "каталогонизатор" по дереву. -- задача из разряда классификации.

Подходил с классического ML

```
Из всех рассмотренных мною вариантов, лучшая метрика получилась c DecisionTreeClassifier 
    - Исследовал данные.
    - Подобран классификатор.
    - Построен пайплайн, почти без трансформаций принимает исходный датасет.
    - В ручную подобраны параметры. Для экономии времени было проще гонять 10 решений одновременно, 
чем в один поток ждать кросс-валидацию
    - Построена метрика по описанию в задании.
    - Результат **0,92** по иерархческому h1
```


Остались задумки по реализации на Bert / LSTM / и других моделях...

